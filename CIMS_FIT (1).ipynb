{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "CIMS FIT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkk-n9Sb88G8"
      },
      "source": [
        "# Temporal Hierarchical Bayesian Causal Inference in Audiovisual Speech Perception\n",
        "\n",
        " - Here we are implementing a modified version of the CIMS model, as first outlined by Magnotti et al., (2013) --> https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00798/full\n",
        " - This specific implementation is testing the predictions of two decision functions, model selection & probability matching, as outlined in Wozny et al., (2010) --> https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000871\n",
        " - Explanations of model derivation, fitting and comparison can be found on the associated github repository --> https://github.com/julesneuro/BCI-Audiovisual-Speech\n",
        " - The entire programme is very computationally expensive due to the trial-wise sampling, I've only tried to run it using colab so I'm sure it'd perform much better on a dedicated workstation. It's also the first computational model of this size I've ever written - so a big learning curve!\n",
        " - At the end of the day each optimization attempt takes about 10 minutes for each model (thus 20 minutes per participant) because of the extensive parameter search conducted in the basinhopping algorithm (and the limitations of google colab). I'd like to parrellise this at some point but I've not had time yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhcbHsSz9BeZ"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numpy import random\n",
        "from scipy.stats import norm, binom\n",
        "from scipy.optimize import minimize, dual_annealing\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "KUH7GBXR87HJ",
        "outputId": "b16b5ccc-936e-40c5-8e3b-4eda3a87a334"
      },
      "source": [
        "# IMPORT DATA\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51cece40-ba72-49e9-a060-7964ee5c85cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-51cece40-ba72-49e9-a060-7964ee5c85cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SIMULATED_DATA.csv to SIMULATED_DATA.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "jd1gzeVLwxD8",
        "outputId": "2228fa84-061b-4df0-a914-7a042e7db396"
      },
      "source": [
        "d = pd.read_csv(\"SIMULATED_DATA.csv\")\n",
        "data = pd.DataFrame(d)\n",
        "\n",
        "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
        "data.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ASYNC_MINUS_300</th>\n",
              "      <th>ASYNC_MINUS_267</th>\n",
              "      <th>ASYNC_MINUS_200</th>\n",
              "      <th>ASYNC_MINUS_133</th>\n",
              "      <th>ASYNC_MINUS_100</th>\n",
              "      <th>ASYNC_MINUS_67</th>\n",
              "      <th>ASYNC_0</th>\n",
              "      <th>ASYNC_PLUS_67</th>\n",
              "      <th>ASYNC_PLUS_100</th>\n",
              "      <th>ASYNC_PLUS_133</th>\n",
              "      <th>ASYNC_PLUS_200</th>\n",
              "      <th>ASYNC_PLUS_267</th>\n",
              "      <th>ASYNC_PLUS_300</th>\n",
              "      <th>ASYNC_PLUS_400</th>\n",
              "      <th>ASYNC_PLUS_500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ASYNC_MINUS_300  ASYNC_MINUS_267  ...  ASYNC_PLUS_400  ASYNC_PLUS_500\n",
              "0                5                4  ...               3               4\n",
              "1                4                4  ...               4               4\n",
              "2                4                2  ...               3               3\n",
              "3                5                3  ...               3               6\n",
              "4                1                4  ...               7               3\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzIAlwBFcdgA"
      },
      "source": [
        "# EXPERIMENTAL PARAMETERS\n",
        "async_conditions = [-300, -267, -200, -133, -100, -67, 0, 67, 100, 133, 200, 267, 300, 400, 500]\n",
        "n_trials = 180 # NEEDS TO BE CHANGED FOR OUR EXPERIMENT\n",
        "trials_per_cond = int(n_trials / len(async_conditions)) \n",
        "\n",
        "# PARAMETERS\n",
        "pc1 = 0.58\n",
        "sens_noise = 100\n",
        "mu1 = 0.0\n",
        "sigma1 = 50\n",
        "mu2 = -48\n",
        "sigma2 = 123\n",
        "\n",
        "exp_params = [async_conditions, n_trials, trials_per_cond]\n",
        "model_params = [pc1, sens_noise, mu1, sigma1, mu2, sigma2]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7_iiXLQc7sz"
      },
      "source": [
        "# DATAFRAME SETUPS\n",
        "params_cols = [\"Participant ID\", \"PC1_MS\", \"SES_NOISE_MS\", \"SIGMA1_MS\", \"MU2_MS\", \"SIGMA2_MS\", \"nLL_MS\", \"R2_MS\",\n",
        "               \"PC1_PM\", \"SES_NOISE_PM\", \"SIGMA1_PM\", \"MU2_PM\", \"SIGMA2_PM\", \"nLL_PM\", \"R2_PM\",\"CHOSEN_STRATEGY\"]\n",
        "params_df = pd.DataFrame(data = None, columns = params_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A8pmFPS9nHm"
      },
      "source": [
        "# MODEL FUNCTIONS\n",
        "\n",
        "def calc_posterior(x, cond, model_params):\n",
        "\n",
        "  \"\"\"Args: x, cond, sens_noise\"\"\"\n",
        "\n",
        "  noise = sens_noise / 2\n",
        "\n",
        "  cond = float(cond) # make sure the condition is a float\n",
        "  var1 = sigma1**2 # transform into variance for the cdf function\n",
        "  var2 = sigma2**2\n",
        "  varx = noise**2\n",
        "\t\n",
        "  lprior = 2 * np.log(pc1 / (1-pc1)) \n",
        "  b = np.log((varx + var2) / (varx + var1)) +  (mu2**2 / (var2 - var1))\n",
        "  c = (1 / (varx + var1)) - (1 / (varx + var2))\n",
        "\n",
        "  if lprior < -b:\n",
        "    lprior = -b\n",
        "\n",
        "  bound = np.sqrt((lprior+b)/c)\n",
        "  middle = abs(mu2) * (varx+var1)/(var2-var1)\n",
        "  upper = middle + bound\n",
        "  lower = middle - bound\n",
        "\n",
        "  one = norm.cdf(x = upper, loc = x, scale = noise)\n",
        "  two = norm.cdf(x = lower, loc = x, scale = noise)\n",
        "\n",
        "  posterior = one - two\n",
        "\n",
        "  return posterior\n",
        "\n",
        "def model_selection(c1_posterior): # CHECKED\n",
        "\n",
        "  \"\"\" Args: c1_posterior (float)\"\"\"\n",
        "\n",
        "  if c1_posterior > 0.5:\n",
        "\n",
        "    return 1 \n",
        "\n",
        "  else:\n",
        "\n",
        "    return 0\n",
        "\n",
        "def probability_matching(c1_posterior): \n",
        "\n",
        "  \"\"\" Args: c1_posterior (float)\"\"\"\n",
        "  \n",
        "  rng = np.random.default_rng()\n",
        "  alpha = rng.uniform(low = 0, high = 1)\n",
        "\n",
        "  if c1_posterior > alpha:\n",
        "\n",
        "    return 1\n",
        "\n",
        "  else:\n",
        "\n",
        "    return 0\n",
        "\n",
        "# HELPER FUNCS\n",
        "\n",
        "def prob_converter(preds, trials_per_cond):\n",
        "\n",
        "  \"\"\"Args: preds, trials_per_cond\"\"\"\n",
        "\n",
        "  prob = preds / trials_per_cond\n",
        "\n",
        "  return prob\n",
        "\n",
        "def clipper(x):\n",
        "  # to stop log divisions by zero when using the loglikelihood!\n",
        "  low = 1e-6\n",
        "  high = (1 - 1e-6)\n",
        "\n",
        "  if x < low:\n",
        "    x = low\n",
        "    return x\n",
        "  elif x > high:\n",
        "    x = high\n",
        "    return x\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "def ll_binomial(p, y, n): \n",
        "\n",
        "  \"\"\"Args: p = prob of success, y = success in observed data,\n",
        "  n = n_trials\"\"\"\n",
        "\n",
        "  # log L(y | p;n) = log(C) + log(p)*y + log(1-p)*(n-y)\n",
        "  p = clipper(p)\n",
        "  q = 1-p\n",
        "  s = y * np.log(p)\n",
        "  f = (n-y) * np.log(q)\n",
        "\t\n",
        "  ll = s + f\n",
        "\n",
        "  return (ll)\n",
        "\n",
        "def calc_nll(success_prob, observed_data, trials_per_cond): \n",
        "\n",
        "  \"\"\"Args: success_prob = prob, observed_data = single item,\n",
        "  trials_per_cond = trials per cond\"\"\"\n",
        "\n",
        "  nll = ll_binomial(success_prob, observed_data, trials_per_cond)\n",
        "  #nLL = nll * -1\n",
        "  \n",
        "  return nll\n",
        "\n",
        "# PREDICT / MAXIMUM LIKELIHOOD EST FUNCTIONS\n",
        "\n",
        "def pred_MS(model_params, exp_params): \n",
        "\n",
        "  \"\"\"Args: arams, exp_params\"\"\"\n",
        "\n",
        "  MS_fpreds = []\n",
        "\n",
        "  noise = sens_noise / 2\n",
        "\n",
        "  for cond in async_conditions:\n",
        "\n",
        "    MS_preds = []\n",
        "\n",
        "    for i in range(trials_per_cond):\n",
        "\n",
        "      x = np.random.normal(loc = cond, scale = noise, size = 1)\n",
        "      posterior = calc_posterior(x, cond, model_params)\n",
        "      MS_pred = model_selection(posterior) \n",
        "      MS_preds.append(MS_pred)\n",
        "      \n",
        "    MS_fin_preds = sum(MS_preds)\n",
        "    MS_fpreds.append(MS_fin_preds) \n",
        "\n",
        "  return MS_fpreds \n",
        "\n",
        "def pred_PM(model_params, exp_params):\n",
        "\n",
        "  \"\"\"Args: model_params, exp_params\"\"\"\n",
        "\n",
        "  PM_fpreds = []\n",
        "\n",
        "  noise = sens_noise / 2\n",
        "\n",
        "  for cond in async_conditions:\n",
        "\n",
        "    PM_preds = []\n",
        "\n",
        "    for i in range(trials_per_cond):\n",
        "\n",
        "      x = np.random.normal(loc = cond, scale = noise, size = 1)\n",
        "\n",
        "      posterior = calc_posterior(x, cond, model_params)\n",
        "      PM_pred = probability_matching(posterior) \n",
        "\n",
        "      PM_preds.append(PM_pred)\n",
        "      \n",
        "    PM_fin_preds = sum(PM_preds)\n",
        "    PM_fpreds.append(PM_fin_preds) \n",
        "\n",
        "  return PM_fpreds\n",
        "\n",
        "def calc_nLL_MS(subject_data, MS_fpreds, trials_per_cond): \n",
        "\n",
        "  \"\"\"Args: Subject_data should be converted into an array, w/o participant ID,\n",
        "  MS_fpreds referes to previous list of predictions, trials_per_cond is an exp_param\"\"\"\n",
        "\n",
        "  nLL_list = [] \n",
        "  \n",
        "  for pred, ob in zip(MS_fpreds, subject_data): \n",
        "               \n",
        "    prob = prob_converter(pred, trials_per_cond)\n",
        "    cond_nLL = calc_nll(prob, ob, trials_per_cond)\n",
        "    nLL_list.append(cond_nLL)\n",
        "\n",
        "  nLL_MS = sum(nLL_list) / 15 \n",
        "\n",
        "  return nLL_MS\n",
        "\n",
        "def calc_nLL_PM(subject_data, PM_fpreds, trials_per_cond): \n",
        "\n",
        "  \"\"\"Args: Subject_data should be converted into an array, w/o participant ID,\n",
        "  MS_fpreds referes to previous list of predictions, trials_per_cond is an exp_param\"\"\"\n",
        "\n",
        "  nLL_list = [] \n",
        "  \n",
        "  for pred, ob in zip(PM_fpreds, subject_data): \n",
        "\n",
        "    prob = prob_converter(pred, trials_per_cond)\n",
        "    cond_nLL = calc_nll(prob, ob, trials_per_cond)\n",
        "    nLL_list.append(cond_nLL)\n",
        "\n",
        "  nLL_PM = sum(nLL_list) / 15 \n",
        "\n",
        "  return nLL_PM\n",
        "\n",
        "def calc_full_nLL_MS(model_params, subject_data, exp_params):\n",
        "  \n",
        "  \"\"\"Args: Subject_data, model_params, exp_params\"\"\"\n",
        "\n",
        "  preds = pred_MS(model_params, exp_params)\n",
        "  nLL_MS = calc_nLL_MS(subject_data, preds, trials_per_cond)\n",
        "\n",
        "  return nLL_MS\n",
        "\n",
        "def calc_full_nLL_PM(model_params, subject_data, exp_params): \n",
        "\n",
        "  \"\"\"Args: Subject_data, model_params, exp_params\"\"\"\n",
        "\n",
        "  preds = pred_PM(model_params, exp_params)\n",
        "  nLL_PM = calc_nLL_PM(subject_data, preds, trials_per_cond)\n",
        "\n",
        "  return nLL_PM\n",
        "\n",
        "# MODEL OPTIMIZATION \n",
        "\n",
        "def cb(x, y, z):\n",
        "\n",
        "  print(x, y)\n",
        "\n",
        "def optimize_global_MS(model_params, subject_data, exp_params):\n",
        "\n",
        "  \"\"\"Args: model_params list, subject_data as an array, \n",
        "    exp_params as a list\"\"\"\n",
        "\n",
        "  bounds = [(0.3,0.7), (0, 500), (0, 500), (-500, 500), (0, 500)]\n",
        "\n",
        "  args = (subject_data, exp_params)\n",
        "  opt_result = dual_annealing(func = calc_full_nLL_MS, args = args, bounds = bounds, maxiter = 100,\n",
        "                              local_search_options = {\"method\":\"SLSQP\"}, callback = cb)\n",
        "  \n",
        "  \n",
        "  fitted_pars_ms = opt_result.x\n",
        "  fitted_preds_ms = opt_result.fun\n",
        "\n",
        "  print(\"It took the CIMS-MS optimizer %s iterations to converge.\" %(opt_result.nit))\n",
        "\n",
        "  return fitted_pars_ms, fitted_preds_ms\n",
        "\n",
        "def optimize_global_PM(model_params, subject_data, exp_params):\n",
        "\n",
        "  \"\"\"Args: model_params list, subject_data as an array, \n",
        "    exp_params as a list\"\"\"\n",
        "\n",
        "  bounds = [(0.3,0.7), (0, 500), (0, 500), (-500, 500), (0, 500)]\n",
        "  \n",
        "  args = (subject_data, exp_params)\n",
        "  opt_result = dual_annealing(func = calc_full_nLL_PM, args = args, bounds = bounds, maxiter = 100,\n",
        "                              local_search_options = {\"method\":\"SLSQP\"}, callback = cb)\n",
        "  \n",
        "  fitted_pars_pm = opt_result.x\n",
        "  fitted_preds_pm = opt_result.fun\n",
        "\n",
        "  print(\"It took the CIMS-PM optimizer %s iterations to converge.\" %(opt_result.nit))\n",
        "\n",
        "  return fitted_pars_pm, fitted_preds_pm\n",
        "\n",
        "# FIT MS\n",
        "\n",
        "def fit_MS(subject_data, model_params, exp_params):\n",
        "\n",
        "  \"\"\"Args: subject_data (array), model_params, exp_params\"\"\"\n",
        "  \n",
        "  fitted_pars_ms, fitted_nll_ms = optimize_global_MS(model_params, subject_data, exp_params)\n",
        "\n",
        "  return fitted_pars_ms, fitted_nll_ms\n",
        "\n",
        "def fit_PM(subject_data, model_params, exp_params):\n",
        "\n",
        "  \"\"\"Args: subject_data (array), model_params, exp_params\"\"\"\n",
        "  \n",
        "  fitted_pars_pm, fitted_nll_pm = optimize_global_PM(model_params, subject_data, exp_params)\n",
        "\n",
        "  return fitted_pars_pm, fitted_nll_pm\n",
        "\n",
        "def fit_models_participant(data_array, model_params, exp_params, participant_ID = int()):\n",
        "\n",
        "  \"\"\"Args: data_df, model_params, exp_params\"\"\"\n",
        "\n",
        "  ID = participant_ID\n",
        "  data = data_array # index\n",
        "\n",
        "  print(\"Fitting CIMS-MS to subject %s\" %(ID))\n",
        "\n",
        "  fitted_pars_ms, fitted_nll_ms = fit_MS(data, model_params, exp_params) \n",
        "  MS_pars_list = [fitted_pars_ms, fitted_nll_ms]\n",
        "  \n",
        "  print(\"Succesfully fitted CIMS-MS to subject %s\" %(ID))\n",
        "  print(\"Fitting CIMS-PM to subject %s\" %(ID))\n",
        "\n",
        "  fitted_pars_pm, fitted_nll_pm = fit_PM(data, model_params, exp_params) \n",
        "  PM_pars_list = [fitted_pars_pm, fitted_nll_pm]\n",
        "\n",
        "  print(\"Succesfully fitted CIMS-PM to subject %s\" %(ID))\n",
        "\n",
        "  return MS_pars_list, PM_pars_list\n",
        "\n",
        "def fit_func(x, model_params, exp_params):\n",
        "\n",
        "  array = data.iloc[x]\n",
        "  array = np.array(array)\n",
        "  print(array)\n",
        "\n",
        "  MS, PM = fit_models_participant(array, \n",
        "                         model_params, exp_params, participant_ID = (x+1))\n",
        "  \n",
        "  return MS, PM\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7udvu4b5Jylo"
      },
      "source": [
        "for x in range(0, 50, 1):\n",
        "\n",
        "  MS, PM = fit_func(x, model_params, exp_params)\n",
        "\n",
        "return MS, PM"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}